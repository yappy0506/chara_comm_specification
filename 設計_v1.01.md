# ソフトウェア設計書（キャラ演技LLM） v1.01

## 0. 目的・スコープ
本設計書は、仕様書 v1.01 に基づき、CUIベースのキャラ演技LLMアプリを実装するための設計を定義する。:contentReference[oaicite:1]{index=1}

### 0.1 スコープ（本設計で実装する）
- CUI（1行入力→1回応答）:contentReference[oaicite:2]{index=2}
- LM Studio(OpenAI互換API)への接続、ヘルスチェック、接続不可時の案内/復帰:contentReference[oaicite:3]{index=3}
- キャラクター設定（profile / speech_style / episodes）をYAMLで管理しSystem Promptに反映:contentReference[oaicite:4]{index=4}
- セッション管理（保存ログはSQLite、逐次保存、再アクセスで継続）:contentReference[oaicite:6]{index=6}
- コマンド：/exit /reset /new /save（最低限）:contentReference[oaicite:7]{index=7}

### 0.2 スコープ外（拡張予定）
感情モデル、長期記憶、マルチモーダル、GUI、Unity統合、並列会話などは本設計では実装しない。:contentReference[oaicite:8]{index=8}

---

## 1. 全体アーキテクチャ

### 1.1 設計原則
- 機能単位で分割し、依存を一方向に保つ（循環依存禁止）:contentReference[oaicite:9]{index=9}
- 将来拡張（GUI/Unity/感情）を阻害しない、薄いUI＋コアロジック中心の構成:contentReference[oaicite:10]{index=10}

### 1.2 レイヤ構造（推奨）
- **UI層**：CUI入出力、コマンド解釈
- **アプリケーション層**：ユースケース（会話1ターン処理、セッション切替）
- **ドメイン層**：会話状態、メッセージ、キャラ設定、プロンプト構築規約
- **インフラ層**：LM Studio APIクライアント、SQLiteリポジトリ、ファイル読込

依存方向：UI → App → Domain → Infra（インタフェースを介して逆依存回避）

### 1.3 コンポーネント図（テキスト）
- CUIController
  - CommandRouter
    - ConversationService（会話1ターン）
      - PromptBuilder（System Prompt生成）
      - LlmClient（LM Studio）
      - MemoryManager（短期履歴の切り詰め）
      - LogRepository（SQLite永続ログ）
    - SessionService（/new /reset /save /exit）

---

## 2. 画面・入出力設計（CUI）

### 2.1 基本動作
- 1行入力を受け取り、1回応答を表示する。:contentReference[oaicite:11]{index=11}
- 出力は「キャラクターの発話のみ」。内部は構造化データ保持可能。:contentReference[oaicite:12]{index=12}

### 2.2 CUI表示仕様（プレースホルダ）
- プロンプト：`<<CHAR_NAME>> > `
- 通常応答：`<<CHAR_NAME>>: <<UTTERANCE>>`
- エラー：`[ERROR] <<MESSAGE>>`
- システム案内：`[INFO] <<MESSAGE>>`

### 2.3 コマンド仕様
- `/exit`
  - 優雅に終了（必要ならフラッシュ保存）
- `/new`
  - 新セッション作成、以降は新セッションへ保存
- `/reset`
  - **LLM投入履歴（短期）**のみクリア（永続ログは維持）※仕様方針に従う:contentReference[oaicite:13]{index=13}
- `/save`
  - 明示的な保存処理（逐次保存が基本でも、将来のエクスポート等のフックとして残す）

---

## 3. 会話処理（ユースケース設計）

### 3.1 ユースケース：1ターン会話（通常入力）
**入力**：ユーザーの1行テキスト  
**出力**：キャラクターの発話テキスト

#### 3.1.1 処理手順（シーケンス）
1. CUIControllerが入力を受ける
2. CommandRouterが先頭文字列を判定（`/`ならコマンド）
3. 通常入力なら ConversationService.handle_turn(session_id, user_text)
4. MemoryManagerが短期履歴（LLM投入履歴）を取得
5. PromptBuilderが System Prompt を生成（キャラ設定YAML → prompt）
6. LlmClientが LM Studio(OpenAI互換API)へ送信
7. 応答を DomainMessage（構造化）へ変換（utterance/emotion/actions）
8. LogRepositoryがユーザー発話・AI発話をSQLiteに逐次保存:contentReference[oaicite:14]{index=14}
9. MemoryManagerが短期履歴に追加し、上限を超えたら古い履歴を破棄:contentReference[oaicite:15]{index=15}
10. CUIに utterance のみ表示:contentReference[oaicite:16]{index=16}

### 3.2 ユースケース：/new
1. SessionService.create_session()
2. session_idを切替
3. 画面に `[INFO] new session: <<session_id>>`

### 3.3 ユースケース：/reset
1. MemoryManager.clear_short_memory(session_id)
2. `[INFO] short memory cleared`
※永続ログは削除しない（セッション継続）:contentReference[oaicite:17]{index=17}

### 3.4 ユースケース：接続不可時
- ヘルスチェック失敗時、手順を表示し入力待ちに復帰する（アプリは終了しない）:contentReference[oaicite:18]{index=18}

---

## 4. キャラクター設定（YAML）設計

### 4.1 ファイル構成（推奨）
```

characters/
<<character_id>>/
profile.yaml
speech_style.yaml
episodes.yaml

```
仕様では profile / 話し方ガイド / episode の3種を想定。:contentReference[oaicite:19]{index=19}

### 4.2 読込ルール
- 起動時に対象キャラID（`<<DEFAULT_CHARACTER_ID>>`）の3ファイルを読み込む
- 読込失敗時の方針（プレースホルダ）
  - `<<ON_CONFIG_LOAD_ERROR>>`：`fail_fast | warn_and_continue | fallback_default`
- schema_version を検証し、互換性がない場合はエラー扱い（推奨）

### 4.3 プロンプト生成規約（PromptBuilder）
**System Prompt**は下記セクションを連結して生成する：
1. **Role**：あなたは <<CHAR_NAME>> として振る舞う
2. **Profile要約**：profile.yamlの主要項目（traits, desires, relationships）
3. **Speech Style**：話し方ガイドの baseline + 該当modeのルール
4. **Prohibited**：禁止事項（メタ発言禁止等）
5. **Episode Telling**：エピソードを話す際のルール（cite_episode_id等）:contentReference[oaicite:20]{index=20}
6. **Output Rule**：CUI表示は発話のみ（内部構造は持ってよい）

#### 4.3.1 エピソード参照ルール（推奨）
- tellable.allow=false のエピソードは会話で明示しない:contentReference[oaicite:21]{index=21}
- reveal_level に応じて詳細度を制限する（hint/normal/full）:contentReference[oaicite:22]{index=22}
- speech_style.yaml の episode_telling.cite_episode_id=false を尊重し、IDは出さない:contentReference[oaicite:23]{index=23}

---

## 5. 会話履歴（短期/永続）設計

### 5.1 短期記憶（LLM投入履歴）
- 直近Nターン（N=<<SHORT_MEMORY_TURNS>>, 初期値100）またはトークン上限まで:contentReference[oaicite:24]{index=24}
- 切り詰め戦略：古いメッセージから削除（ユーザー/AIをペアで削除推奨）

### 5.2 永続ログ（SQLite）
- 全会話をSQLiteに逐次保存:contentReference[oaicite:25]{index=25}
- セッション再アクセスにより会話を継続できる:contentReference[oaicite:26]{index=26}

### 5.3 容量制限
- 最大セッション数：MAX_SESSION_COUNT=<<MAX_SESSION_COUNT>> を超えたら古いセッションから削除:contentReference[oaicite:27]{index=27}

---

## 6. データモデル設計

### 6.1 Domainモデル（Python）
- Session
  - id: str
  - character_id: str
  - created_at: datetime
  - updated_at: datetime
- Message
  - id: str
  - session_id: str
  - role: "user" | "assistant" | "system"
  - content: str
  - created_at: datetime
  - meta_json: dict（将来：emotion/actions等）
- CharacterProfile（profile.yaml）
- SpeechStyle（speech_style.yaml）
- Episodes（episodes.yaml）

### 6.2 内部構造化応答（将来拡張の下地）
- utterance: str
- emotion: dict（現状は空）
- actions: list（現状は空）
仕様で内部は構造化保持可能とする。:contentReference[oaicite:28]{index=28}

---

## 7. DB設計（SQLite）

### 7.1 テーブル構成（提案）
#### sessions
- session_id TEXT PRIMARY KEY
- character_id TEXT NOT NULL
- title TEXT NULL（任意：最初のユーザー発話等）
- created_at TEXT NOT NULL
- updated_at TEXT NOT NULL

#### messages
- message_id TEXT PRIMARY KEY
- session_id TEXT NOT NULL
- role TEXT NOT NULL CHECK(role IN ('user','assistant','system'))
- content TEXT NOT NULL
- meta_json TEXT NOT NULL DEFAULT '{}'  -- JSON文字列
- created_at TEXT NOT NULL
- FOREIGN KEY(session_id) REFERENCES sessions(session_id)

### 7.2 インデックス
- messages(session_id, created_at)
- sessions(updated_at)

### 7.3 容量制限の実装方針
- 起動時またはセッション作成時に sessions 件数を確認
- 超過していれば古いsessionsから削除（CASCADEでmessagesも削除）

---

## 8. LM Studio 接続設計

### 8.1 接続先設定（プレースホルダ）
- base_url: `<<LMSTUDIO_BASE_URL>>`（例：`http://127.0.0.1:1234/v1`）
- model: `<<LMSTUDIO_MODEL>>`（例：`openai/gpt-oss-20b`）
- timeout_sec: `<<LLM_TIMEOUT_SEC>>`（例：60）

### 8.2 ヘルスチェック
- 例：`GET <<base_url>>/models` を実施
- 期待：HTTP 200、対象modelが存在

### 8.3 接続不可時の挙動
仕様に従い、ベストエフォートで自動起動/有効化を試みつつ、
最低限は「必要手順を表示し復帰可能」とする。:contentReference[oaicite:29]{index=29}

---

## 9. エラー処理設計

### 9.1 タイムアウト
- LLM呼び出しがtimeoutしたら：
  - `[ERROR] generation timeout`
  - 入力待ちに戻る:contentReference[oaicite:30]{index=30}

### 9.2 コンテキスト過長
- トークン上限を超える場合：
  - 古い履歴から削除して再試行（最大<<RETRY_MAX>>回）
  - それでも不可なら `[ERROR] context too long` を表示:contentReference[oaicite:31]{index=31}

### 9.3 想定外例外
- スタックトレースはログに記録し、画面には要点のみ表示
- 継続可能なら入力待ちに復帰、致命的なら安全終了:contentReference[oaicite:32]{index=32}

---

## 10. モジュール設計

### 10.1 ディレクトリ案
```

app/
**main**.py
ui/
cui_controller.py
command_router.py
usecases/
conversation_service.py
session_service.py
domain/
models.py
prompt_builder.py
memory_manager.py
character_loader.py
infra/
llm_client.py
db.py
repositories.py
config/
settings.py
characters/
<<character_id>>/
profile.yaml
speech_style.yaml
episodes.yaml
data/
app.db
logs/
app.log

```

### 10.2 主要クラスと責務
- CUIController
  - 入力ループ、表示、例外キャッチの最上位
- CommandRouter
  - `/`コマンド判定・ディスパッチ
- ConversationService
  - 1ターン処理のオーケストレーション
- PromptBuilder
  - YAML設定→System Prompt組み立て
- MemoryManager
  - 短期履歴の追加・切り詰め・クリア
- LlmClient
  - LM Studio API 呼び出し、タイムアウト/リトライ
- LogRepository
  - SQLiteへの永続化・取得・削除（容量制限含む）
- CharacterLoader
  - profile/speech_style/episodes のロードと検証

---

## 11. 設定（Config）設計

### 11.1 設定値一覧（例）
- DEFAULT_CHARACTER_ID=<<DEFAULT_CHARACTER_ID>>
- SHORT_MEMORY_TURNS=<<SHORT_MEMORY_TURNS>>（初期100）
- MAX_SESSION_COUNT=<<MAX_SESSION_COUNT>>
- LMSTUDIO_BASE_URL=<<LMSTUDIO_BASE_URL>>
- LMSTUDIO_MODEL=<<LMSTUDIO_MODEL>>
- LLM_TIMEOUT_SEC=<<LLM_TIMEOUT_SEC>>
- RETRY_MAX=<<RETRY_MAX>>
- DB_PATH=<<DB_PATH>>

### 11.2 設定読み込み優先順位（推奨）
1. コマンドライン引数（任意）
2. 環境変数
3. `config/settings.yaml`（任意）
4. デフォルト値

---

## 12. テスト方針（最小）
- 単体テスト
  - PromptBuilder：同一入力で同一prompt（スナップショット）
  - MemoryManager：切り詰め境界、/reset
  - LogRepository：insert/select、容量制限削除
- 疎通テスト
  - LM Studio未起動→案内表示→復帰
  - 1ターン会話→保存→再起動→同セッション再開

---

## 13. 未決定事項（プレースホルダ）
- <<DEFAULT_CHARACTER_ID>>：デフォルトキャラクターID
- <<MAX_SESSION_COUNT>>：最大セッション数
- <<LMSTUDIO_BASE_URL>>：LM Studio API URL
- <<LLM_TIMEOUT_SEC>>：タイムアウト秒
- <<ON_CONFIG_LOAD_ERROR>>：設定ファイル読込失敗時の方針
- YAMLの厳密スキーマ検証方式（pydantic等）採用有無

